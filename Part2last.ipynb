{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/resh1604/SIT742/blob/master/Part2last.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pCbBuHhutRJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6a38f8c3-e2bf-419e-876f-c368ec1b5d6d"
      },
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZR6V0YwNtWAg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import wget\n",
        "\n",
        "link_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2019/data/wine.json'\n",
        "DataSet = wget.download(link_to_data)\n",
        "\n",
        "link_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2019/data/stopwords.txt'\n",
        "\n",
        "DataSet = wget.download(link_to_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3H4keZsdtY5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_GTqBC0BtbUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.probability import *\n",
        "from itertools import chain\n",
        "#from tqdm import tqdm\n",
        "import codecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LiQV8yFttdm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "6aa4b378-e3a4-4cd5-8721-8222fdce69ec"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('reuters')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "uRgl5Fw7tgWq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = 'wine.json'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dRwGxuhItiu4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_json(file, orient='columns')\n",
        "#df.head(10)\n",
        "#print(df)\n",
        "#print(df.to_json(orient='index', lines='True'))\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "peN63EzdtraD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p2d1 = df.loc[df['variety'] == 'Shiraz']\n",
        "p2d1\n",
        "\n",
        "p2d2 = p2d1[['description','variety']]\n",
        "p2d2\n",
        "\n",
        "p2d3 = p2d1[['description']]\n",
        "p2d3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12z5JnthC7b5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('stopwords.txt') as f:\n",
        "    stop_words = f.read().splitlines()\n",
        "stop_words = set(stop_words)\n",
        "stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nm-Boj3qB4kZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "5427e17e-b5d6-4ed3-ba77-f4cee4e320a2"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "import os\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "path = './tf-idf'\n",
        "token_dict = open('stopwords.txt', 'r+')\n",
        "\n",
        "\n",
        "def tokenize(p2d3):\n",
        "    tokens = nltk.word_tokenize(p2d3)\n",
        "    stems = []\n",
        "    for item in tokens:\n",
        "        stems.append(PorterStemmer().stem(item))\n",
        "    return stems\n",
        "\n",
        "for dirpath, dirs, files in os.walk(path):\n",
        "    for f in files:\n",
        "        fname = os.path.join(dirpath, f)\n",
        "        print(\"fname= \", fname)\n",
        "        with open(fname) as pearl:\n",
        "            text = pearl.read()\n",
        "            token_dict[f] = text.lower().translate(None, string.punctuation)\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenize, input=file)\n",
        "tfs = tfidf.fit_transform(token_dict)\n",
        "\n",
        "str = 'all great and precious things are lonely.'\n",
        "response = tfidf.transform([str])\n",
        "print(response)\n",
        "\n",
        "feature_names = tfidf.get_feature_names()\n",
        "for col in response.nonzero()[1]:\n",
        "    print(feature_names[col], ' - ', response[0, col])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 45)\t0.5531796154731755\n",
            "  (0, 32)\t0.5890637966404614\n",
            "  (0, 19)\t0.5890637966404614\n",
            "are  -  0.5531796154731755\n",
            "and  -  0.5890637966404614\n",
            "all  -  0.5890637966404614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2PvqHdY0FQBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0f776ef3-b82f-4014-b310-16eced4e631b"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words='english')\n",
        "X = vectorizer.fit_transform(p2d3)\n",
        "X = vectorizer.transform(p2d3)\n",
        "idf = vectorizer.idf_\n",
        "print(dict(zip(vectorizer.get_feature_names(), idf)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'description': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}